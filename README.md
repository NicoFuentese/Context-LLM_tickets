# Smart-IT Ops: GLPi Intelligent Advisor

Asistente basado en IA para infraestructura TI, dise√±ado para analizar cargas de trabajo de GLPi y sugerir asignaciones √≥ptimas.

# Contexto del Proyecto: Problem√°tica y Soluci√≥n

## üî¥ La Problem√°tica (Legacy Ops)

En la operaci√≥n diaria de una Mesa de Ayuda (Service Desk), los coordinadores y Tech Leads enfrentan tres desaf√≠os cr√≠ticos que ralentizan el tiempo de resoluci√≥n (MTTR):

1. Ceguera Operativa: Asignar tickets bas√°ndose en la intuici√≥n en lugar de datos reales. Es dif√≠cil saber qui√©n est√° saturado y qui√©n est√° libre sin revisar m√∫ltiples reportes.

2. Fatiga de Decisi√≥n: Leer descripciones t√©cnicas complejas para decidir si un ticket es de "Redes", "Servidores" o "Soporte N1" consume tiempo valioso.

3. Riesgo de Seguridad en IA: El uso de herramientas p√∫blicas (como ChatGPT web) para analizar tickets implica un riesgo alto de fuga de datos (PII, contrase√±as, IPs internas).

## üü¢ La Soluci√≥n: Smart-IT Ops (Arquitectura)

Smart-IT es un sistema de Asistencia Operativa Basada en Contexto de Tecnicos y Tickets.

### Flujo de Datos (Arquitectura RAG Lite)

El sistema utiliza un enfoque de Retrieval-Augmented Generation (RAG) simplificado para garantizar que la IA nunca "alucine" datos ni invente t√©cnicos que no existen.

```mermaid
graph LR
    A[GLPi Export] -->|tickets.csv| B(Pandas Engine)
    B -->|1. Filtra Tickets Activos| C{L√≥gica Python}
    B -->|2. Busca ID Espec√≠fico| C
    C -->|Inyecta Contexto Real| D[Prompt del Sistema]
    E[Pregunta Usuario] --> D
    D -->|Contexto + Pregunta| F[LLM Gemini 2.5 flash-Lite]
    F -->|Recomendaci√≥n Segura| G[Streamlit UI]
```

## Estrategia del LLM

Para lograr respuestas precisas y seguras, implementamos tres capas de control en el modelo de lenguaje:

1. Inyecci√≥n Din√°mica de Contexto: La IA no tiene "memoria" de tu empresa. En cada consulta, el sistema inyecta en tiempo real la tabla de carga laboral (T√©cnico A: 5 tickets, T√©cnico B: 0 tickets) y el detalle del ticket consultado. Esto fuerza al modelo a responder bas√°ndose matem√°ticamente en la carga actual.

2. Guardrails de Privacidad (Sanitizaci√≥n): A trav√©s de Prompt Engineering defensivo, el sistema est√° instruido para detectar patrones sensibles (IPs, Hashes, Contrase√±as) y censurarlos o ignorarlos antes de generar una respuesta, protegiendo la integridad de la infraestructura.

3. Determinismo sobre Creatividad: Configuramos el modelo con una temperatura baja (0.3). No queremos un poeta; queremos un ingeniero. Las respuestas son directas, t√©cnicas y justificadas con datos ("Asigna a X porque tiene Y carga").

## üìã Requisitos Previos
- Windows 11 (PowerShell)
- Python 3.10+
- Acceso a GLPi (para exportar CSV)
- Google Gemini API Key

## üöÄ Instalaci√≥n y Despliegue (Windows)

### 1. Preparar el Entorno

#### Windows
Abrir PowerShell en la carpeta ra√≠z del proyecto:

```powershell
# Crear entorno virtual
python -m venv venv

# Activar entorno (Windows)
.\venv\Scripts\Activate.ps1

# Instalar dependencias
pip install -r requirements.txt

# Desactivar entorno (Windows)
deactivate
```

#### Ubuntu
```powershell
# Crear entorno virtual
python3 -m venv venv

# Activar entorno (ubuntu)
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt

# Desactivar entorno (ubuntu)
deactivate
```

## ‚öôÔ∏è Configuraci√≥n de Variables de Entorno (.env)

El archivo .env act√∫a como una "caja fuerte" que guarda sus claves secretas y preferencias locales.

### Pasos para crearlo:
1. Navegue a la carpeta ra√≠z del proyecto.
2. Cree un nuevo archivo de texto vac√≠o.
3. Ren√≥mbrelo a: .env (Importante eliminar el formato .txt).
4. Abra el archivo con un editor de texto y pegue el siguiente contenido:

```
# ==========================================
# CONFIGURACI√ìN DE APP
# ==========================================

# [OBLIGATORIO] API Key de Google Gemini
# Obt√©ngala aqu√≠: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=pegue_aqui_su_api_key_sin_comillas

# [OPCIONAL]
GLPI_CSV_FILENAME=tickets.csv
```

# Tu VS Code no te reconoce tus dependencias?
Esto ocurre porque VS Code esta "mirando" tu Python global para hacer el autocompletado y la revision de errores.

### Para arreglarlo selecciona el interprete Correcto:
    1. Presiona Ctrl + Shift + P (o Cmd + Shift + P en Mac) para abrir la paleta de comandos.
    2. Escribe y selecciona: Python: Select Interpreter.
    3. Ver√°s una lista. Busca la opci√≥n que diga algo como:
     - Python 3.x.x ('venv': venv) üëà Esta es la correcta.
     - O que tenga la ruta ./venv/Scripts/python.exe.
    4. Selecci√≥nala.
    5. Espera unos segundos. El error de Pylance deber√≠a desaparecer.

# Quieres consultar los modelos que tienes disponibles?
```powershell
#Encontrar modelos disponibles de Gemini
cd .\services\
python test_models.py
```

# Para correr la aplicaci√≥n
```powershell
#Correr proyecto
streamlit run app.py
```

# üèóÔ∏è Arquitectura de la Soluci√≥n

El siguiente diagrama ilustra el flujo de datos entre el usuario, la capa l√≥gica en AWS y el servicio de IA.

```mermaid
graph TD
    subgraph "Local / Origen"
        GLPi[("GLPi - Sistema Tickets")]
        Admin("Admin TI")
    end

    subgraph "Entorno Virtual o VM"
        direction TB
        CSV[("üìÇ data/tickets.csv")]
        Env{".env API Keys"}
        
        subgraph "Aplicaci√≥n Python"
            UI[("üñ•Ô∏è Streamlit Frontend")]
            Logic["‚öôÔ∏è App Logic Backend"]
            Repo["üîç Repository Pandas"]
            Service["üß† LLM Service"]
        end
    end

    subgraph "Nube Externa"
        Gemini("‚òÅÔ∏è Google Gemini API")
    end

    %% Flujo de Datos
    GLPi -.->|Exportaci√≥n Manual/Diaria| CSV
    Admin -->|Consulta via Browser :8501| UI
    
    %% Proceso Interno
    UI -->|1. Input Usuario| Logic
    Logic -->|2. Solicitar Datos| Repo
    Repo -->|3. Leer y Calcular Carga| CSV
    Repo -->|4. Retornar Estado Equipo| Logic
    
    Logic -->|5. Cargar Credenciales| Env
    Logic -->|6. Enviar Prompt y Contexto| Service
    
    %% IA
    Service -->|7. Request HTTPS| Gemini
    Gemini -->|8. Response Recomendaci√≥n| Service
    
    %% Respuesta Final
    Service -->|9. Texto Procesado| Logic
    Logic -->|10. Mostrar Respuesta| UI
```

# Pruebas de uso LLM

*Prompt:* "Recomienda un t√©cnico para el id [ID_REAL]"

*Prompt:* "Analiza el ticket #[ID_REAL] y dime qu√© habilidades t√©cnicas necesita el t√©cnico para resolverlo."

*Prompt:* ""Tengo un ticket de mantenimiento general muy sencillo. ¬øA qui√©n deber√≠a asign√°rselo para no sobrecargar al equipo?""

*Prompt:* "Asigna el ticket #[ID_DE_REDES]. Es urgente."

*Prompt:* "Si llega un ticket cr√≠tico sobre ca√≠da del Firewall, ¬øqui√©n es el m√°s apto para verlo seg√∫n la carga actual?"
