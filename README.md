# Smart-IT Ops: GLPi Intelligent Advisor

Asistente basado en IA para infraestructura TI, diseÃ±ado para analizar cargas de trabajo de GLPi y sugerir asignaciones Ã³ptimas.

# Contexto del Proyecto: ProblemÃ¡tica y SoluciÃ³n

## ðŸ”´ La ProblemÃ¡tica (Legacy Ops)

En la operaciÃ³n diaria de una Mesa de Ayuda (Service Desk), los coordinadores y Tech Leads enfrentan tres desafÃ­os crÃ­ticos que ralentizan el tiempo de resoluciÃ³n (MTTR):

1. Ceguera Operativa: Asignar tickets basÃ¡ndose en la intuiciÃ³n en lugar de datos reales. Es difÃ­cil saber quiÃ©n estÃ¡ saturado y quiÃ©n estÃ¡ libre sin revisar mÃºltiples reportes.

2. Fatiga de DecisiÃ³n: Leer descripciones tÃ©cnicas complejas para decidir si un ticket es de "Redes", "Servidores" o "Soporte N1" consume tiempo valioso.

3. Riesgo de Seguridad en IA: El uso de herramientas pÃºblicas (como ChatGPT web) para analizar tickets implica un riesgo alto de fuga de datos (PII, contraseÃ±as, IPs internas).

## ðŸŸ¢ La SoluciÃ³n: Smart-IT Ops (Arquitectura)

Smart-IT es un sistema de Asistencia Operativa Basada en Contexto de Tecnicos y Tickets.

### Flujo de Datos (Arquitectura RAG Lite)

El sistema utiliza un enfoque de Retrieval-Augmented Generation (RAG) simplificado para garantizar que la IA nunca "alucine" datos ni invente tÃ©cnicos que no existen.

```mermaid
graph LR
    A[GLPi Export] -->|tickets.csv| B(Pandas Engine)
    B -->|1. Filtra Tickets Activos| C{LÃ³gica Python}
    B -->|2. Busca ID EspecÃ­fico| C
    C -->|Inyecta Contexto Real| D[Prompt del Sistema]
    E[Pregunta Usuario] --> D
    D -->|Contexto + Pregunta| F[Google Gemini LLM]
    F -->|RecomendaciÃ³n Segura| G[Streamlit UI]
```

## Estrategia del LLM

Para lograr respuestas precisas y seguras, implementamos tres capas de control en el modelo de lenguaje:

1. InyecciÃ³n DinÃ¡mica de Contexto: La IA no tiene "memoria" de tu empresa. En cada consulta, el sistema inyecta en tiempo real la tabla de carga laboral (TÃ©cnico A: 5 tickets, TÃ©cnico B: 0 tickets) y el detalle del ticket consultado. Esto fuerza al modelo a responder basÃ¡ndose matemÃ¡ticamente en la carga actual.

2. Guardrails de Privacidad (SanitizaciÃ³n): A travÃ©s de Prompt Engineering defensivo, el sistema estÃ¡ instruido para detectar patrones sensibles (IPs, Hashes, ContraseÃ±as) y censurarlos o ignorarlos antes de generar una respuesta, protegiendo la integridad de la infraestructura.

3. Determinismo sobre Creatividad: Configuramos el modelo con una temperatura baja (0.3). No queremos un poeta; queremos un ingeniero. Las respuestas son directas, tÃ©cnicas y justificadas con datos ("Asigna a X porque tiene Y carga").

## ðŸ“‹ Requisitos Previos
- Windows 11 (PowerShell)
- Python 3.10+
- Acceso a GLPi (para exportar CSV)
- Google Gemini API Key

## ðŸš€ InstalaciÃ³n y Despliegue (Windows)

### 1. Preparar el Entorno

#### Windows
Abrir PowerShell en la carpeta raÃ­z del proyecto:

```powershell
# Crear entorno virtual
python -m venv venv

# Activar entorno (Windows)
.\venv\Scripts\Activate.ps1

# Instalar dependencias
pip install -r requirements.txt

# Desactivar entorno (Windows)
deactivate
```

#### Ubuntu
```powershell
# Crear entorno virtual
python3 -m venv venv

# Activar entorno (ubuntu)
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt

# Desactivar entorno (ubuntu)
deactivate
```

## âš™ï¸ ConfiguraciÃ³n de Variables de Entorno (.env)

El archivo .env actÃºa como una "caja fuerte" que guarda sus claves secretas y preferencias locales.

### Pasos para crearlo:
1. Navegue a la carpeta raÃ­z del proyecto.
2. Cree un nuevo archivo de texto vacÃ­o.
3. RenÃ³mbrelo a: .env (Importante eliminar el formato .txt).
4. Abra el archivo con un editor de texto y pegue el siguiente contenido:

```
# ==========================================
# CONFIGURACIÃ“N DE APP
# ==========================================

# [OBLIGATORIO] API Key de Google Gemini
# ObtÃ©ngala aquÃ­: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=pegue_aqui_su_api_key_sin_comillas

# [OPCIONAL]
GLPI_CSV_FILENAME=tickets.csv
```

# Tu VS Code no te reconoce tus dependencias?
Esto ocurre porque VS Code esta "mirando" tu Python global para hacer el autocompletado y la revision de errores.

### Para arreglarlo selecciona el interprete Correcto:
    1. Presiona Ctrl + Shift + P (o Cmd + Shift + P en Mac) para abrir la paleta de comandos.
    2. Escribe y selecciona: Python: Select Interpreter.
    3. VerÃ¡s una lista. Busca la opciÃ³n que diga algo como:
     - Python 3.x.x ('venv': venv) ðŸ‘ˆ Esta es la correcta.
     - O que tenga la ruta ./venv/Scripts/python.exe.
    4. SelecciÃ³nala.
    5. Espera unos segundos. El error de Pylance deberÃ­a desaparecer.

# Quieres consultar los modelos que tienes disponibles?
```powershell
#Encontrar modelos disponibles de Gemini
cd .\services\
python test_models.py
```

# Para correr la aplicaciÃ³n
```powershell
#Correr proyecto
streamlit run app.py
```

## ðŸ—ï¸ Arquitectura de la SoluciÃ³n

El siguiente diagrama ilustra el flujo de datos entre el usuario, la capa lÃ³gica en AWS y el servicio de IA.

```mermaid
graph TD
    subgraph "Local / Origen"
        GLPi[("GLPi - Sistema Tickets")]
        Admin("Admin TI")
    end

    subgraph "Entorno Virtual o VM"
        direction TB
        CSV[("ðŸ“‚ data/tickets.csv")]
        Env{".env API Keys"}
        
        subgraph "AplicaciÃ³n Python"
            UI[("ðŸ–¥ï¸ Streamlit Frontend")]
            Logic["âš™ï¸ App Logic Backend"]
            Repo["ðŸ” Repository Pandas"]
            Service["ðŸ§  LLM Service"]
        end
    end

    subgraph "Nube Externa"
        Gemini("â˜ï¸ Google Gemini API")
    end

    %% Flujo de Datos
    GLPi -.->|ExportaciÃ³n Manual/Diaria| CSV
    Admin -->|Consulta via Browser :8501| UI
    
    %% Proceso Interno
    UI -->|1. Input Usuario| Logic
    Logic -->|2. Solicitar Datos| Repo
    Repo -->|3. Leer y Calcular Carga| CSV
    Repo -->|4. Retornar Estado Equipo| Logic
    
    Logic -->|5. Cargar Credenciales| Env
    Logic -->|6. Enviar Prompt y Contexto| Service
    
    %% IA
    Service -->|7. Request HTTPS| Gemini
    Gemini -->|8. Response RecomendaciÃ³n| Service
    
    %% Respuesta Final
    Service -->|9. Texto Procesado| Logic
    Logic -->|10. Mostrar Respuesta| UI
```
